{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import ssl\n",
    "import pandas as pd\n",
    "from utils.model_utils import UNet, store_tested_parameters, train_and_get_validation_loss, train_with_early_stopping\n",
    "from utils.image_utils import CustomImageDataset\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "torch.hub.set_dir(d = \"C:\\\\Users\\\\Ugne\\\\torch\\\\hub\")\n",
    "\n",
    "data_dir = \"images\"\n",
    "device = \"cuda\"\n",
    "classes =  [\"Person\", \"Skyscraper\", \"Car\"]\n",
    "\n",
    "class_mapping = {'Skyscraper': 1, 'Car': 2, 'Person': 3}\n",
    "\n",
    "def get_dir_for_class(class_name, masks_or_images=\"images\"):\n",
    "    return data_dir+\"/\"+class_name.lower()+\"/\"+masks_or_images\n",
    "\n",
    "download_dirs = [get_dir_for_class(c) for c in classes]+[\"images/all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_annotations = pd.read_csv(\"downloaded_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    #transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    #transforms.RandomAffine(degrees = 20, scale = (0.7,1.3)),\n",
    "    #transforms.ColorJitter(brightness=.5, hue=.3)\n",
    "])\n",
    "\n",
    "target_size = (64,64)\n",
    "\n",
    "train_dataset = CustomImageDataset(image_dir=\"images/all\", class_annotations=downloaded_annotations, class_mapping=class_mapping, \n",
    "                                   transform=transform, dataset_type=\"train\", target_size=target_size)\n",
    "validation_dataset = CustomImageDataset(image_dir=\"images/all\", class_annotations=downloaded_annotations, class_mapping=class_mapping, \n",
    "                                        transform=None, dataset_type=\"validation\", target_size=target_size)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search for best batch size and learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the optimal batch size and learning rate using Bayesian optimization. The acquisition function uses a Gaussian prior (assumes a normal distribution), which allows the next parameter to be chosen in a smarter way, cutting down on the exploration time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.7179199543866244\n",
      "Epoch 2/5, Loss: 0.6315036621960727\n",
      "Epoch 3/5, Loss: 0.6077892411838878\n",
      "Epoch 4/5, Loss: 0.581497938524593\n",
      "Epoch 5/5, Loss: 0.5606708813797344\n",
      "Validation Loss: 0.5728951518734297\n",
      "Epoch 1/5, Loss: 0.7209381649368688\n",
      "Epoch 2/5, Loss: 0.6467689699248264\n",
      "Epoch 3/5, Loss: 0.6063428254503953\n",
      "Epoch 4/5, Loss: 0.5680287425455294\n",
      "Epoch 5/5, Loss: 0.5535448813124707\n",
      "Validation Loss: 0.6104296578301324\n",
      "Epoch 1/5, Loss: 0.749743123099489\n",
      "Epoch 2/5, Loss: 0.5289105997895295\n",
      "Epoch 3/5, Loss: 0.4861830084953668\n",
      "Epoch 4/5, Loss: 0.46409777706524113\n",
      "Epoch 5/5, Loss: 0.442688579829234\n",
      "Validation Loss: 0.564777279065715\n",
      "Epoch 1/5, Loss: 1.219102081325319\n",
      "Epoch 2/5, Loss: 0.9603706189879665\n",
      "Epoch 3/5, Loss: 0.8601658465685668\n",
      "Epoch 4/5, Loss: 0.7940411771889087\n",
      "Epoch 5/5, Loss: 0.7422260951112818\n",
      "Validation Loss: 0.9102703796492683\n",
      "Epoch 1/5, Loss: 0.6138759932275546\n",
      "Epoch 2/5, Loss: 0.5020155537936647\n",
      "Epoch 3/5, Loss: 0.47578804750563736\n",
      "Epoch 4/5, Loss: 0.46260472652265583\n",
      "Epoch 5/5, Loss: 0.4468557261309381\n",
      "Validation Loss: 0.6356703349285655\n",
      "Epoch 1/5, Loss: 0.7358738154172897\n",
      "Epoch 2/5, Loss: 0.5241063483059406\n",
      "Epoch 3/5, Loss: 0.49462722763419154\n",
      "Epoch 4/5, Loss: 0.4739325769245625\n",
      "Epoch 5/5, Loss: 0.45166284441947935\n",
      "Validation Loss: 0.5124143039186796\n",
      "Epoch 1/5, Loss: 0.671076596860426\n",
      "Epoch 2/5, Loss: 0.6029644328427602\n",
      "Epoch 3/5, Loss: 0.5637528142297125\n",
      "Epoch 4/5, Loss: 0.5448136875428349\n",
      "Epoch 5/5, Loss: 0.524526972009475\n",
      "Validation Loss: 0.5395898901753955\n",
      "Epoch 1/5, Loss: 0.6473049456253648\n",
      "Epoch 2/5, Loss: 0.5500805238261819\n",
      "Epoch 3/5, Loss: 0.5089379750813047\n",
      "Epoch 4/5, Loss: 0.4944750002274911\n",
      "Epoch 5/5, Loss: 0.47107586078345776\n",
      "Validation Loss: 0.6562855235404439\n",
      "Epoch 1/5, Loss: 0.7805139889771288\n",
      "Epoch 2/5, Loss: 0.673022825609554\n",
      "Epoch 3/5, Loss: 0.6738990552046082\n",
      "Epoch 4/5, Loss: 0.6702502247962084\n",
      "Epoch 5/5, Loss: 0.6703192083673044\n",
      "Validation Loss: 0.6139820623728964\n",
      "Epoch 1/5, Loss: 0.6771139807230688\n",
      "Epoch 2/5, Loss: 0.646262624472246\n",
      "Epoch 3/5, Loss: 0.6431455292776561\n",
      "Epoch 4/5, Loss: 0.6393429596862451\n",
      "Epoch 5/5, Loss: 0.6256553177876323\n",
      "Validation Loss: 0.6341484619511498\n"
     ]
    }
   ],
   "source": [
    "space = [Integer(1,128, name=\"batch_size\"),\n",
    "         Real(10**-5, 10**0, \"log-uniform\", name=\"learning_rate\")]\n",
    "\n",
    "num_epochs = 5\n",
    "device = \"cuda\"\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    model = UNet().to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    batch_size = int(params['batch_size'])\n",
    "    learning_rate = params['learning_rate']\n",
    "    \n",
    "    validation_loss = train_and_get_validation_loss(model, train_dataset, validation_dataset, criterion, batch_size, learning_rate)\n",
    "    \n",
    "    return validation_loss\n",
    "\n",
    "res_gp = gp_minimize(objective, space, n_calls=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 0.0025112263624837016, 18.446914941072464)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_batch_size, best_learning_rate = res_gp.x\n",
    "best_score = res_gp.fun\n",
    "all_scores = res_gp.func_vals\n",
    "\n",
    "store_tested_parameters(res_gp)\n",
    "\n",
    "best_batch_size, best_learning_rate, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_params_backup = (104, 0.0025112263624837016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model using optimal batch size and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = UNet()\n",
    "best_model.to(device)\n",
    "num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "validation_loss = train_and_get_validation_loss(best_model, train_dataset, validation_dataset, criterion, batch_size=int(best_batch_size), learning_rate=best_learning_rate)\n",
    "\n",
    "torch.save(best_model.state_dict(), \"best_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have selected the optimal batch size and learning rate using a small number of epochs. This only holds under the assumption that the same optimal batch size and learning rate will minimise validation loss for a small number of epochs as it would for a larger number of epochs - this assumption may not always hold in practice.\n",
    "\n",
    "Now, we should use these parameters and implement early stopping to select the optimal number of epochs.\n",
    "\n",
    "Early stopping means that if the model does not reach an improvement in the validation set for a set number of epochs (equal to the **patience** parameter), we stop the training early on. This should help us combat overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 0.6823548190295696\n",
      "Epoch 1/20, Validation Loss: 0.6535208410507923\n",
      "Early stopping counter: 0 out of 3\n",
      "Epoch 2/20, Training Loss: 0.4969502218067646\n",
      "Epoch 2/20, Validation Loss: 1.6184678786509745\n",
      "Early stopping counter: 1 out of 3\n",
      "Epoch 3/20, Training Loss: 0.46710917428135873\n",
      "Epoch 3/20, Validation Loss: 0.5965611991044637\n",
      "Early stopping counter: 0 out of 3\n",
      "Epoch 4/20, Training Loss: 0.4483248800039291\n",
      "Epoch 4/20, Validation Loss: 0.579216471394977\n",
      "Early stopping counter: 0 out of 3\n",
      "Epoch 5/20, Training Loss: 0.4401305727660656\n",
      "Epoch 5/20, Validation Loss: 0.5969279593712574\n",
      "Early stopping counter: 1 out of 3\n",
      "Epoch 6/20, Training Loss: 0.42813734859228136\n",
      "Epoch 6/20, Validation Loss: 0.604693432917466\n",
      "Early stopping counter: 2 out of 3\n",
      "Epoch 7/20, Training Loss: 0.41338326409459114\n",
      "Epoch 7/20, Validation Loss: 0.5493906937740944\n",
      "Early stopping counter: 0 out of 3\n",
      "Epoch 8/20, Training Loss: 0.40500504747033117\n",
      "Epoch 8/20, Validation Loss: 0.5417567362656465\n",
      "Early stopping counter: 0 out of 3\n",
      "Epoch 9/20, Training Loss: 0.3945510469377041\n",
      "Epoch 9/20, Validation Loss: 0.8120572204525406\n",
      "Early stopping counter: 1 out of 3\n",
      "Epoch 10/20, Training Loss: 0.39788061678409575\n",
      "Epoch 10/20, Validation Loss: 0.6137456942248989\n",
      "Early stopping counter: 2 out of 3\n",
      "Epoch 11/20, Training Loss: 0.3841736987233162\n",
      "Epoch 11/20, Validation Loss: 0.5596644000427143\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.366947948932648"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_v2 = UNet()\n",
    "best_model_v2.to(device)\n",
    "\n",
    "optimal_train_dataloader = DataLoader(train_dataset, batch_size=int(best_batch_size), shuffle=True, drop_last=True)\n",
    "optimal_optimizer = torch.optim.Adam(best_model_v2.parameters(), lr=best_learning_rate)\n",
    "\n",
    "train_with_early_stopping(best_model_v2, optimal_optimizer, criterion=criterion, dataloader=optimal_train_dataloader, val_dataloader=validation_dataloader, num_epochs=20, patience=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
